from time import sleep
import modal
import modal
import os
import subprocess
from pathlib import Path
import shutil
from pathlib import Path
import json

import datetime
import subprocess
import shutil
import datetime
from pathlib import Path
import json
import os

app = modal.App("ktv-processor")

def correct_lyrics_with_gemini(api_key: str, raw_text: str, song_metadata: str) -> str:
    from google import genai
    from google.genai import types
    """
    ä½¿ç”¨ Gemini æœç´¢å¹¶ä¿®æ­£æ­Œè¯
    raw_text: Whisper è¯†åˆ«å‡ºçš„ç²—ç³™æ–‡æœ¬
    song_metadata: "æ­Œå - æ­Œæ‰‹"
    """
    client = genai.Client(api_key=api_key)
    
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­—å¹•æ ¡å¯¹å‘˜ã€‚
    
    ä»»åŠ¡ï¼š
    1. æˆ‘ä¼šç»™ä½ ä¸€æ®µç”± AI è¯­éŸ³è¯†åˆ«ç”Ÿæˆçš„ç²—ç³™æ­Œè¯ï¼ˆå¯èƒ½åŒ…å«é”™åˆ«å­—ã€åŒéŸ³è¯é”™è¯¯ï¼‰ã€‚
    2. æ­Œæ›²ä¿¡æ¯æ˜¯ï¼šã€{song_metadata}ã€‘ã€‚
    3. è¯·åˆ©ç”¨ä½ çš„çŸ¥è¯†åº“æˆ–æœç´¢èƒ½åŠ›ï¼Œæ‰¾åˆ°è¿™é¦–æ­Œçš„**å®˜æ–¹æ­£ç¡®æ­Œè¯**ã€‚
    4. å¯¹æ¯”æˆ‘æä¾›çš„ç²—ç³™æ–‡æœ¬ï¼Œè¾“å‡ºä¿®æ­£åçš„ã€åˆ†è¡Œæ­£ç¡®çš„**çº¯æ­Œè¯**ã€‚
    5. **ä¸¥ç¦**è¾“å‡ºä»»ä½•æ—¶é—´è½´ã€è§£é‡Šã€å‰è¨€æˆ–åç¼€ã€‚åªè¾“å‡ºæ­Œè¯å†…å®¹ã€‚
    6. ä¿æŒåŸæ›²çš„æ®µè½ç»“æ„ã€‚
    
    ç²—ç³™æ­Œè¯è¾“å…¥ï¼š
    {raw_text}
    """
    tools = [
        types.Tool(
            google_search=types.GoogleSearch() # å¯ç”¨å†…ç½®æœç´¢
        )
    ]
    
    try:
        response = client.models.generate_content(
            model="gemini-3-pro-preview", # æ¨èç”¨ Flashï¼Œé€Ÿåº¦å¿«ä¸”æœç´¢èƒ½åŠ›å¼º
            contents=prompt,
            config=types.GenerateContentConfig(
                tools=tools,
                response_modalities=["TEXT"], # ç¡®ä¿åªè¿”å›æ–‡æœ¬
                temperature=0.1 # ä½æ¸©åº¦ï¼Œç¡®ä¿å‡†ç¡®æ€§
            )
        )
        
        # 3. è·å–ç»“æœ
        # æ–° SDK çš„ response.text ç›´æ¥å¯ç”¨ï¼Œå¦‚æœæœ‰ grounding metadata ä¹Ÿå¯ä»¥åœ¨è¿™é‡ŒæŸ¥
        corrected_text = response.text.strip()
        
        # ç®€å•çš„åå¤„ç†ï¼šå»é™¤å¯èƒ½çš„ Markdown ä»£ç å—æ ‡è®°
        corrected_text = corrected_text.replace("```lyric", "").replace("```text", "").replace("```", "").strip()
        return corrected_text
    except Exception as e:
        print(f"Gemini ä¿®æ­£å¤±è´¥: {e}")
        return raw_text # å¤±è´¥é™çº§ï¼šç›´æ¥è¿”å›åŸæ–‡æœ¬

# 1. å®šä¹‰ä¸€ä¸ªæŒä¹…åŒ–å­˜å‚¨å·ï¼Œåå­—å« "ktv-data"
# create_if_missing=True ä¼šè‡ªåŠ¨åˆ›å»ºå®ƒ
volume = modal.Volume.from_name("data", create_if_missing=True)

# 2. å®šä¹‰ä¸€ä¸ªâ€œæ¬è¿å·¥â€å‡½æ•°
# å®ƒæŒ‚è½½äº† volume åˆ° /data ç›®å½•
@app.function(volumes={"/data": volume})
def save_file_to_volume(file_content: bytes, remote_filename: str):
    remote_path = f"/data/{remote_filename}"
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(remote_path), exist_ok=True)
    
    print(f"æ­£åœ¨å†™å…¥æ–‡ä»¶åˆ°: {remote_path}...")
    with open(remote_path, "wb") as f:
        f.write(file_content)
    
    # ã€å…³é”®ã€‘å¼ºåˆ¶æäº¤æ›´æ”¹ï¼Œè¿™æ ·å…¶ä»–å‡½æ•°ï¼ˆæ¯”å¦‚ä½ çš„ GPU å‡½æ•°ï¼‰èƒ½ç«‹å³çœ‹åˆ°è¿™ä¸ªæ–‡ä»¶
    volume.commit() 
    print("å†™å…¥å®Œæˆå¹¶å·²æäº¤ Volumeã€‚")

# ---------------------------------------------------------
# 1. å®šä¹‰ä¸€ä¸ªäº‘ç«¯åŠ©æ‰‹å‡½æ•°ï¼šåªè´Ÿè´£æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
# ---------------------------------------------------------
@app.function(volumes={"/data": volume})
def check_file_exists(remote_filename: str):
    """
    è¿è¡Œåœ¨äº‘ç«¯ï¼Œæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç»åœ¨ Volume é‡Œäº†
    """
    remote_path = Path("/data") / remote_filename
    exists = remote_path.exists()
    if not exists:
        return exists, 0
    size_mb = remote_path.stat().st_size / (1024 * 1024) if exists else 0
    return exists, size_mb

image = (
    modal.Image.debian_slim()
    .pip_install("demucs", "torch", "torchaudio", "soundfile", "numpy", "stable-ts", "faster-whisper")
    # 2. ã€å…³é”®ã€‘å®‰è£…ç³»ç»Ÿçº§ä¾èµ– ffmpeg (åŒ…å« ffprobe)
    .apt_install("ffmpeg", "libsndfile1")
    # 3. ã€å…³é”®ä¿®æ”¹ã€‘æŠŠ google-genai å•ç‹¬æ”¾ä¸€è¡Œï¼Œå¼ºåˆ¶é‡æ–°æ„å»º
    # åŒæ—¶æŒ‡å®šç‰ˆæœ¬å· (>=0.3.0) ç¡®ä¿æ˜¯æ”¯æŒ from google import genai çš„æ–°ç‰ˆ
    .pip_install("google-genai>=0.3.0")
    .pip_install("audio-separator[gpu]")
    # é¢„ä¸‹è½½æ¨¡å‹åˆ°é•œåƒé‡Œï¼ŒåŠ å¿«å¯åŠ¨é€Ÿåº¦
    .run_commands("python3 -c 'from demucs.pretrained import get_model; get_model(\"htdemucs\")'")
)

@app.function(
    image=image,
    gpu="L4",
    volumes={"/data": volume},
    timeout=600
)
def demucsFn(remote_filename: str):
    import torch
    from demucs.pretrained import get_model
    from demucs.apply import apply_model  # <--- ä¿®æ”¹è¿™é‡Œ
    from demucs.audio import AudioFile, save_audio
    import soundfile as sf  # <--- å¼•å…¥ soundfile

    from demucs.apply import apply_model
    from demucs.pretrained import get_model
    from demucs.audio import save_audio, AudioFile

    print(f"ğŸš€ [Remote] å¼€å§‹å¤„ç†: {remote_filename}")
    
    input_path = Path("/data") / remote_filename
    output_dir = input_path.parent
    
    # åŠ è½½æ¨¡å‹
    model = get_model("htdemucs")
    model.to("cuda")
    
    # è¯»å–éŸ³é¢‘
    wav = AudioFile(input_path).read(
        streams=0, samplerate=model.samplerate, channels=model.audio_channels
    )
    ref = wav.mean(0)
    wav = (wav - ref.mean()) / ref.std()
    
    # <--- ä¿®æ”¹è¿™é‡Œ: ä½¿ç”¨ apply_model
    sources = apply_model(
        model, 
        wav[None], 
        device="cuda", 
        shifts=1, 
        split=True, 
        overlap=0.25, 
        progress=True
    )[0]
    
    sources = sources * ref.std() + ref.mean()
    
    # åç»­å¤„ç†ä¿æŒä¸å˜...
    vocab_idx = model.sources.index("vocals")
    vocals_wav = sources[vocab_idx]
    
    other_indices = [i for i in range(len(model.sources)) if i != vocab_idx]
    instr_wav = torch.zeros_like(vocals_wav)
    for i in other_indices:
        instr_wav += sources[i]
        
    vocals_out = output_dir / "vocals.wav"
    instr_out = output_dir / "instrumental.wav"
    
    print(f"ğŸ’¾ ä¿å­˜äººå£°åˆ°: {vocals_out}")
    
    # ã€å…³é”®ä¿®æ”¹ã€‘ä½¿ç”¨ soundfile ç›´æ¥å†™å…¥
    # 1. .cpu().numpy(): æŠŠ Tensor è½¬æˆ numpy æ•°ç»„
    # 2. .T: è½¬ç½®ã€‚å› ä¸º Tensor æ˜¯ [å£°é“, æ—¶é•¿]ï¼Œä½† soundfile éœ€è¦ [æ—¶é•¿, å£°é“]
    sf.write(str(vocals_out), vocals_wav.cpu().numpy().T, model.samplerate)
    
    print(f"ğŸ’¾ ä¿å­˜ä¼´å¥åˆ°: {instr_out}")
    sf.write(str(instr_out), instr_wav.cpu().numpy().T, model.samplerate)
    
    return {
        "vocals": str(vocals_out),
        "instrumental": str(instr_out)
    }

@app.function(image=image, gpu="L4", volumes={"/data": volume})
def demucs_fn_v2(remote_path: str) -> bool:
    from audio_separator.separator import Separator
    import shutil
    
    base_path = Path("/data") / remote_path
    base_path = base_path.parent
    input_file = base_path / "original.wav"
    model_path = Path("model")
    
    # åˆå§‹åŒ–
    separator = Separator(
        model_file_dir=model_path,  # <--- ã€å…³é”®ã€‘å‘Šè¯‰åº“ï¼šå»è¿™ä¸ªç›®å½•æ‰¾æ–‡ä»¶
        output_dir=str(base_path),
        output_format="wav"
    )

    # --- ç¬¬ä¸€æ­¥ï¼šç”¨ ViperX åšé«˜è´¨é‡åŸºåº•åˆ†ç¦» ---
    print("STEP 1: åˆ†ç¦»ä¼´å¥ä¸äººå£° (ViperX)...")
    separator.load_model(model_filename="model_bs_roformer_ep_317_sdr_12.9755.ckpt")
    outputs_1 = separator.separate(str(input_file))
    
    # å‡è®¾ outputs_1[0] æ˜¯ Instrumental, outputs_1[1] æ˜¯ Vocals
    # æ³¨æ„ï¼šaudio-separator çš„è¿”å›é¡ºåºå¯èƒ½éœ€è¦é€šè¿‡æ–‡ä»¶ååˆ¤æ–­ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
    inst_path = base_path / outputs_1[0] 
    vocals_path = base_path / outputs_1[1]

    # --- ç¬¬äºŒæ­¥ï¼šä»äººå£°ä¸­æå–å’Œå£° (Karaoke Model) ---
    print("STEP 2: ä»äººå£°ä¸­æå–å’Œå£° (Mel-Band Karaoke)...")
    # è¿™ä¸ªæ¨¡å‹ä¸“é—¨æŠŠ Vocals æ‹†æˆ "Lead" å’Œ "Backing"
    separator.load_model(model_filename="mel_band_roformer_karaoke_becruily.ckpt")
    outputs_2 = separator.separate(str(vocals_path))
    
    # outputs_2 é‡Œåº”è¯¥æœ‰ä¸€ä¸ªæ˜¯ backing vocals (å’Œå£°)
    # å‡è®¾ outputs_2[0] æ˜¯ backing, outputs_2[1] æ˜¯ lead
    backing_path = base_path / outputs_2[0]
    lead_vocal_path = base_path / outputs_2[1]
    os.rename(lead_vocal_path, base_path / "vocals.wav")
    
    # --- ç¬¬ä¸‰æ­¥ï¼šåˆå¹¶ (ffmpeg) ---
    print("STEP 3: åˆå¹¶ çº¯ä¼´å¥ + å’Œå£°...")
    # ä½¿ç”¨ ffmpeg mix ä¸¤ä¸ªéŸ³é¢‘
    final_inst = base_path / "instrumental.wav"
    
    import subprocess
    cmd = [
        "ffmpeg", "-y",
        "-i", str(inst_path),
        "-i", str(backing_path),
        "-filter_complex", "amix=inputs=2:duration=longest",
        str(final_inst)
    ]
    try:
        subprocess.run(cmd, check=True)
    except subprocess.CalledProcessError as e:
        print(f"âŒ ffmpeg åˆå¹¶å¤±è´¥: {e}")
        return False
    
    print(f"ğŸ‰ å®Œç¾ KTV ä¼´å¥å·²ç”Ÿæˆ: {final_inst}")
    return True

@app.function(
    image=image,
    gpu="L4",  # L4 è·‘è¿™ä¸ªæ¨¡å‹éå¸¸å¿«ï¼Œæ€§ä»·æ¯”æœ€é«˜
    volumes={"/data": volume},
    timeout=600
)
def process_audio_for_ktv(remote_filename: str):
    from audio_separator.separator import Separator

    print(f"ğŸš€ [Remote] å¼€å§‹é«˜è´¨é‡ KTV åˆ†ç¦»: {remote_filename}")
    
    # è·¯å¾„å¤„ç† (ä¿æŒå’Œä½ åŸé€»è¾‘ä¸€è‡´)
    input_path = Path("/data") / remote_filename
    output_dir = input_path.parent
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir.mkdir(parents=True, exist_ok=True)

    # åˆå§‹åŒ–åˆ†ç¦»å™¨
    # model_file_dir='/data/models': æŠŠæ¨¡å‹ç¼“å­˜åœ¨ Volume é‡Œï¼Œé˜²æ­¢æ¯æ¬¡å†·å¯åŠ¨éƒ½ä¸‹è½½
    separator = Separator(
        log_level='INFO',
        model_file_dir='/data/models', 
        output_dir=str(output_dir),
        output_format='wav',
        normalization_threshold=0.9 # é˜²æ­¢çˆ†éŸ³
    )

    # åŠ è½½ KTV ä¸“ç”¨æ¨¡å‹ (ä¿ç•™å’Œå£°)
    # ç¬¬ä¸€æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½
    separator.load_model(model_filename='UVR-MDX-NET-Karaoke-2.mdx')

    # æ‰§è¡Œåˆ†ç¦»
    print(f"ğŸ”„ æ­£åœ¨è¿è¡Œ UVR-MDX-NET-Karaoke-2 æ¨ç†...")
    output_files = separator.separate(str(input_path))
    
    # --- å…³é”®æ­¥éª¤ï¼šé‡å‘½åä»¥åŒ¹é…æ¥å£ ---
    # audio-separator ç”Ÿæˆçš„æ–‡ä»¶åé€šå¸¸å¸¦æœ‰æ¨¡å‹åç¼€ï¼Œæ¯”å¦‚ "åŸæ–‡ä»¶å_(Vocals)_UVR...wav"
    # æˆ‘ä»¬éœ€è¦æŠŠå®ƒä»¬é‡å‘½åä¸º "vocals.wav" å’Œ "instrumental.wav"
    
    final_vocals_path = output_dir / "vocals.wav"
    final_instr_path = output_dir / "instrumental.wav"

    for fname in output_files:
        original_file_path = output_dir / fname
        
        # é€»è¾‘åˆ¤æ–­ï¼šå“ªä¸ªæ˜¯äººå£°ï¼Œå“ªä¸ªæ˜¯ä¼´å¥
        # UVR-MDX-NET-Karaoke-2 çš„è¾“å‡ºé€šå¸¸åŒ…å« "Vocals" å’Œ "Instrumental"
        if "Vocals" in fname:
            # ç§»åŠ¨å¹¶è¦†ç›– (å¦‚æœæœ‰æ—§æ–‡ä»¶)
            shutil.move(str(original_file_path), str(final_vocals_path))
            print(f"ğŸ’¾ é‡å‘½åäººå£°ä¸º: {final_vocals_path}")
            
        elif "Instrumental" in fname:
            shutil.move(str(original_file_path), str(final_instr_path))
            print(f"ğŸ’¾ é‡å‘½åä¼´å¥ä¸º: {final_instr_path}")

    # æ¸…ç†æ˜¾å­˜
    del separator
    import torch
    torch.cuda.empty_cache()

    # è¿”å›å’Œä½ åŸå‡½æ•°å®Œå…¨ä¸€è‡´çš„å­—å…¸ç»“æ„
    return {
        "vocals": str(final_vocals_path),
        "instrumental": str(final_instr_path)
    }

@app.function(
    image=image,
    gpu="L4",
    volumes={"/data": volume},
    secrets=[modal.Secret.from_name("app-secret")],
    timeout=600
)
def transcribe(title: str, artist: str, audio_path: str):
    
    import stable_whisper
    device = 'cuda'
    print(f"[STEP 4] Transcribing using Stable-TS on {device}...")
    input_path = Path("/data") / audio_path
    output_dir = input_path.parent
    output_ass_path = output_dir / "lyrics.ass"

    model = stable_whisper.load_faster_whisper(
        "large-v3-turbo",  # æˆ–è€… "large-v3-turbo"
        device="cuda",
        compute_type="float16" # L4 ä¸Šç”¨ float16 åŠ é€Ÿ
    )

    # 2. è·å–æ­£ç¡®æ–‡æœ¬
    result = model.transcribe(
        str(input_path),
        language="zh",
        regroup=True,
        vad=True,          # ã€å…³é”®ã€‘å¼€å¯ VAD è¿‡æ»¤é—´å¥
        vad_parameters={
            "threshold": 0.5,               # ä¹‹å‰å»ºè®®çš„ 0.5
            "min_speech_duration_ms": 300,  # 0.3ç§’ -> 300æ¯«ç§’
            "min_silence_duration_ms": 500, # 0.5ç§’ -> 500æ¯«ç§’ (å¯é€‰ï¼Œç”¨äºæ–­å¥)
            # "speech_pad_ms": 400          # å¯é€‰ï¼šå‰åå¤šç•™ä¸€ç‚¹å£°éŸ³ï¼Œé˜²æ­¢åˆ‡è¯å¤ªç‹ 
        },
    )
    gemini_key = os.environ["GEMINI_KEY"]
    text = correct_lyrics_with_gemini(gemini_key, result.text, f"{title} - {artist}")

    print("ğŸ“ ä¿®æ­£åçš„æ­Œè¯é¢„è§ˆ:")
    print(text[:100] + "...")

    # === 3. ä¿®æ­£åçš„ Align (å»æ‰æŠ¥é”™å‚æ•°) ===
    # align çš„ä½œç”¨åªæ˜¯æŠŠçº¯æ–‡æœ¬ç²—ç•¥åœ°æ˜ å°„å›éŸ³é¢‘ï¼Œä¸éœ€è¦å¤ªå¤æ‚çš„å‚æ•°
    result = model.align(
        str(input_path), 
        text, 
        language="zh",
        original_split=True, # ä¿ç•™ Gemini çš„åˆ†è¡Œ
        # å¦‚æœä½ ç”¨äº† VADï¼Œalign å†…éƒ¨ä¹Ÿä¼šå°è¯•åˆ©ç”¨ï¼Œä½†ä¸è¦æ‰‹åŠ¨ä¼  skip_non_speech
    )
    
    # === 4. å…³é”®æ­¥éª¤: Refine (è¿™æ‰æ˜¯è§£å†³â€œæŠ¢è·‘â€çš„æ ¸å¿ƒ) ===
    # refine ä¼šé‡æ–°æ‰«æéŸ³é¢‘æ³¢å½¢ï¼ŒæŠŠå¯¹é½åçš„å•è¯è¾¹ç•Œâ€œå¸é™„â€åˆ°æœ€è¿‘çš„çœŸå®å‘éŸ³ä¸Š
    # è¿™æ­¥èƒ½è§£å†³ 90% çš„â€œæ­Œè¯æå‰æ˜¾ç¤ºâ€é—®é¢˜
    print("[STEP 3.5] Refining timestamps...")
    model.refine(
        str(input_path),
        result,  # æŠŠåˆšæ‰ align å¾—åˆ°çš„ç»“æœä¼ è¿›å»
        precision=0.05,
        # è¿™é‡Œçš„å‚æ•°æ˜¯ç»™ VAD æˆ–è€… demucs ç”¨çš„ï¼Œå¦‚æœä¸ç”¨ demucs å¯ä»¥ä¸ä¼ 
    )
    
    # 3. å…³é”®è½¬æ¢ï¼
    # æˆ‘ä»¬ä¸è°ƒç”¨ result.to_ass()ï¼Œå› ä¸ºå®ƒçš„æ ·å¼å¤ªä¸‘ä¸”é€»è¾‘ä¸ç¬¦åˆ KTVã€‚
    # æˆ‘ä»¬æŠŠ result è½¬æˆ dictï¼Œç›´æ¥å–‚ç»™æˆ‘å†™çš„é‚£ä¸ª generate_karaoke_ass å‡½æ•°ã€‚
    # stable-ts çš„ result.to_dict() ç»“æ„å’Œ WhisperX/OpenAI æ˜¯ä¸€æ¨¡ä¸€æ ·çš„ã€‚
    data = result.to_dict()

    tmp_whisper_file = output_ass_path.parent / "tmp_whisper.json"
    with open(tmp_whisper_file, "w", encoding='utf-8') as f:
        json.dump(data, f, indent=4, ensure_ascii=False)
    
    # 4. ç”Ÿæˆä¸“ä¸š KTV å­—å¹•
    # è¿™é‡Œè°ƒç”¨çš„æ˜¯ä½ è„šæœ¬é‡Œå®šä¹‰çš„é‚£ä¸ªå‡½æ•°
    # generate_karaoke_ass(data, output_ass_path)
    generate_karaoke_ass_v2(data, output_ass_path)
    
    print(f"[INFO] Saved Customized KTV ASS to {output_ass_path}")

def format_ass_timestamp(seconds):
    """Converts seconds to ASS timestamp format H:MM:SS.cs"""
    td = datetime.timedelta(seconds=seconds)
    total_seconds = int(td.total_seconds())
    hours = total_seconds // 3600
    minutes = (total_seconds % 3600) // 60
    secs = total_seconds % 60
    centiseconds = int(round((seconds - total_seconds) * 100))
    return f"{hours}:{minutes:02d}:{secs:02d}.{centiseconds:02d}"

def generate_karaoke_ass(whisper_result, output_path, max_chars_per_line=16):
    """
    ç”Ÿæˆ KTV å­—å¹•ï¼šé•¿å¥è‡ªåŠ¨æŠ˜è¡Œ (Wrap)ï¼Œè€Œä¸æ˜¯åˆ‡åˆ†ã€‚
    max_chars_per_line: è¶…è¿‡è¿™ä¸ªå­—æ•°ï¼Œå°±åœ¨ä¸­é—´æ’å…¥æ¢è¡Œç¬¦
    """
    
    # === 1. å®šä¹‰ ASS å¤´éƒ¨ ===
    # æ³¨æ„ WrapStyle: 2 (ä¸è‡ªåŠ¨æ¢è¡Œ)ï¼Œæˆ‘ä»¬è¦è‡ªå·±æ§åˆ¶æ¢è¡Œ
    header = (
        "[Script Info]\n"
        "ScriptType: v4.00+\n"
        "PlayResX: 1920\n"
        "PlayResY: 1080\n"
        "WrapStyle: 2\n" 
        "\n"
        "[V4+ Styles]\n"
        "Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, "
        "Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, "
        "Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\n"
        # Alignment: 2 (åº•éƒ¨å±…ä¸­)ã€‚è¿™æ ·æ¢è¡Œæ—¶ï¼Œç¬¬ä¸€è¡Œä¼šåœ¨ç¬¬äºŒè¡Œçš„ä¸Šé¢ã€‚
        "Style: KTV,Arial,80,&H0000FFFF,&H00FFFFFF,&H00000000,&H80000000,-1,0,0,0,100,100,0,0,1,2,0,2,135,135,60,1\n"
        "\n"
        "[Events]\n"
        "Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n"
    )
    
    lines = [header]
    
    if "segments" not in whisper_result:
        print("[WARN] No segments found.")
        return

    # === 2. ä¸»å¾ªç¯å¤„ç† ===
    for segment in whisper_result["segments"]:
        start_t = format_ass_timestamp(segment["start"])
        end_t = format_ass_timestamp(segment["end"])
        
        words = segment.get("words", [])
        text_len = len(segment.get("text", ""))
        
        # --- æ ¸å¿ƒé€»è¾‘ï¼šè®¡ç®—æ¢è¡Œç‚¹ ---
        split_idx = -1
        # å¦‚æœå¥å­æ€»é•¿åº¦è¶…è¿‡é™åˆ¶ (æ¯”å¦‚ 16ä¸ªå­—)
        if text_len > max_chars_per_line and len(words) > 1:
            # æˆ‘ä»¬åœ¨å•è¯åˆ—è¡¨çš„ä¸­é—´ä½ç½®æ’å…¥æ¢è¡Œç¬¦
            split_idx = len(words) // 2 

        ktv_text = ""
        cursor = segment["start"]

        if words:
            for i, word in enumerate(words):
                # 1. æ£€æŸ¥æ˜¯å¦éœ€è¦æ’å…¥æ¢è¡Œç¬¦
                # å¦‚æœå½“å‰è¯æ˜¯å‰åŠæ®µçš„æœ€åä¸€ä¸ªè¯ä¹‹åï¼Œæ’å…¥ \N
                if i == split_idx:
                    ktv_text += r"\N" # ASS çš„ç¡¬æ¢è¡Œç¬¦
                
                # 2. å¤„ç†æ—¶é—´è½´ (Gap & Duration)
                w_start = word.get("start", cursor)
                w_end = word.get("end", w_start + 0.1)
                
                # Gap (ç©ºéš™)
                gap = int(round((w_start - cursor) * 100))
                if gap > 1:
                    ktv_text += f"{{\\k{gap}}}"
                
                # Fill (æ­Œè¯å˜è‰²)
                duration = int(round((w_end - w_start) * 100))
                word_text = word["word"]
                
                ktv_text += f"{{\\kf{duration}}}{word_text}"
                
                cursor = w_end
        else:
            # Fallback: æ²¡æœ‰è¯çº§æ—¶é—´è½´æ—¶çš„å¤„ç†
            raw_text = segment["text"]
            # å¦‚æœæ²¡æ—¶é—´è½´ä½†ä¹Ÿå¤ªé•¿ï¼Œæ‰‹åŠ¨å¼ºè¡Œæ’ä¸ª \N åœ¨ä¸­é—´
            if len(raw_text) > max_chars_per_line:
                mid = len(raw_text) // 2
                ktv_text = raw_text[:mid] + r"\N" + raw_text[mid:]
            else:
                ktv_text = raw_text

        lines.append(f"Dialogue: 0,{start_t},{end_t},KTV,,0,0,0,,{ktv_text}")

    with open(output_path, "w", encoding="utf-8") as f:
        f.write("\n".join(lines))
    print(f"[INFO] Wrapped ASS file saved to: {output_path}")

def generate_karaoke_ass_v2(whisper_result, output_path, max_chars_per_line=16):
    """
    ç”Ÿæˆ KTV å­—å¹•ï¼š
    1. å¼ºåˆ¶ä»¥ word['start'] ä¸ºåŸºå‡†ï¼Œå¿½ç•¥ segment é€ æˆçš„æ¼‚ç§»ã€‚
    2. å¢åŠ  Lead-in (æå‰è¿›åœºæ—¶é—´)ï¼Œé¿å…æ­Œè¯è·³å‡ºæ¥ç¬é—´å°±å¼€å§‹å”±ã€‚
    """
    
    header = (
        "[Script Info]\n"
        "ScriptType: v4.00+\n"
        "PlayResX: 1920\n"
        "PlayResY: 1080\n"
        "WrapStyle: 2\n" 
        "\n"
        "[V4+ Styles]\n"
        "Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, "
        "Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, "
        "Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\n"
        "Style: KTV,Arial,80,&H0000FFFF,&H00FFFFFF,&H00000000,&H80000000,-1,0,0,0,100,100,0,0,1,2,0,2,135,135,60,1\n"
        "\n"
        "[Events]\n"
        "Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n"
    )
    
    lines = [header]
    
    if "segments" not in whisper_result:
        return

    # é¢„ç•™æ—¶é—´ï¼šå­—å¹•æ¯”äººå£°æ—©å‡ºæ¥å¤šå°‘ç§’ (é€šå¸¸ 0.5s - 1.0s)
    LEAD_IN_BUFFER = 0.5 
    # é€€å‡ºç¼“å†²ï¼šå­—å¹•å”±å®Œåå¤šåœç•™å¤šä¹…
    LEAD_OUT_BUFFER = 0.5

    for segment in whisper_result["segments"]:
        words = segment.get("words", [])
        
        # === æ ¸å¿ƒä¿®æ­£ 1: å…œåº•å¤„ç† ===
        if not words:
            # å¦‚æœæ²¡æœ‰è¯çº§æ—¶é—´è½´ï¼ˆå¯¹é½å¤±è´¥ï¼‰ï¼Œå›é€€åˆ° segment æ—¶é—´
            start_t = format_ass_timestamp(segment["start"])
            end_t = format_ass_timestamp(segment["end"])
            lines.append(f"Dialogue: 0,{start_t},{end_t},KTV,,0,0,0,,{segment['text']}")
            continue

        # === æ ¸å¿ƒä¿®æ­£ 2: é‡æ„ Line Start/End ===
        # å³ä½¿ segment['start'] æ˜¯ 10.0s (å› ä¸ºåŒ…å«äº†è¢«åˆ çš„è¯­æ°”è¯)ï¼Œ
        # å¦‚æœ words[0]['start'] æ˜¯ 15.0sï¼Œæˆ‘ä»¬å°±ä» 14.5s å¼€å§‹æ˜¾ç¤ºå­—å¹•ã€‚
        
        real_start = words[0]['start']
        real_end = words[-1]['end']
        
        # è®¡ç®— ASS è¡Œçš„æ˜¾ç¤ºæ—¶é—´
        ass_start_time = max(0, real_start - LEAD_IN_BUFFER)
        ass_end_time = real_end + LEAD_OUT_BUFFER
        
        start_t = format_ass_timestamp(ass_start_time)
        end_t = format_ass_timestamp(ass_end_time)

        # === æ ¸å¿ƒä¿®æ­£ 3: è®¡ç®—æŠ˜è¡Œ ===
        text_len = len(segment.get("text", ""))
        split_idx = -1
        if text_len > max_chars_per_line and len(words) > 1:
            split_idx = len(words) // 2 

        ktv_text = ""
        
        # cursor ç°åœ¨çš„åˆå§‹å€¼æ˜¯ ASS è¡Œçš„å¼€å§‹æ—¶é—´ (æ¯”å¦‚ 14.5s)
        # è€Œç¬¬ä¸€ä¸ªè¯å¼€å§‹æ˜¯ 15.0s
        # å®ƒä»¬ä¹‹é—´çš„å·®å€¼ (0.5s) å°±æ˜¯ç¬¬ä¸€ä¸ª \k çš„ç­‰å¾…æ—¶é—´
        cursor = ass_start_time

        for i, word in enumerate(words):
            if i == split_idx:
                ktv_text += r"\N"

            w_start = word.get("start")
            w_end = word.get("end")

            # --- å…³é”® Gap è®¡ç®— ---
            # è®¡ç®—å½“å‰è¯å¼€å§‹æ—¶é—´ ä¸ å…‰æ ‡ä½ç½® çš„å·®å€¼
            # åªæœ‰å½“ w_start > cursor æ—¶æ‰ä¼šæœ‰æ­£å€¼çš„ gap
            # round(x * 100) è½¬æ¢æˆå˜ç§’
            gap_duration = int(round((w_start - cursor) * 100))
            
            # å¦‚æœ Gap åªæœ‰ 1cs (0.01s) è¿™ç§æå°å€¼ï¼Œå¾€å¾€æ˜¯æµ®ç‚¹è¯¯å·®ï¼Œå¯ä»¥å¿½ç•¥
            # ä½†å¦‚æœæ˜¯é¦–è¯ (i==0)ï¼Œgap_duration åŒ…å«äº† LEAD_INï¼Œå¿…é¡»ä¿ç•™
            if gap_duration > 0:
                ktv_text += f"{{\\k{gap_duration}}}"
            
            # --- å•è¯æŒç»­æ—¶é—´ ---
            word_duration = int(round((w_end - w_start) * 100))
            # æœ€å°ç»™ 1csï¼Œé˜²æ­¢ \kf0 å¯¼è‡´æ¸²æŸ“å™¨æŠ¥é”™
            word_duration = max(1, word_duration)
            
            ktv_text += f"{{\\kf{word_duration}}}{word['word']}"
            
            # æ›´æ–°å…‰æ ‡åˆ°å½“å‰è¯ç»“æŸ
            cursor = w_end

        lines.append(f"Dialogue: 0,{start_t},{end_t},KTV,,0,0,0,,{ktv_text}")

    with open(output_path, "w", encoding="utf-8") as f:
        f.write("\n".join(lines))
    print(f"[INFO] Robust KTV ASS file saved to: {output_path}")

def download_if_not_exist(remote_filename: str, local_path: str):
    """
    ä» Modal Volume ä¸‹è½½æ–‡ä»¶åˆ°æœ¬åœ°
    remote_filename: Volume ä¸­çš„ç›¸å¯¹è·¯å¾„ (ä¾‹å¦‚ "EqCmAYywrwI/baked.mkv")
    local_path: æœ¬åœ°ä¿å­˜è·¯å¾„ (ä¾‹å¦‚ "./output/final.mkv")
    """
    local_file = Path(local_path)
    
    # 1. æ£€æŸ¥æœ¬åœ°æ˜¯å¦å·²å­˜åœ¨
    if local_file.exists():
        print(f"âœ… æœ¬åœ°æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½: {local_path}")
        return True

    # ç¡®ä¿æœ¬åœ°çˆ¶ç›®å½•å­˜åœ¨
    local_file.parent.mkdir(parents=True, exist_ok=True)

    remote_file = remote_filename

    print(f"ğŸ“¥ å¼€å§‹ä¸‹è½½: {remote_file} -> {local_path} ...")
    
    # 2. è°ƒç”¨ Modal CLI ä¸‹è½½
    # æ ¼å¼: modal volume get <Volumeå> <è¿œç¨‹è·¯å¾„> <æœ¬åœ°è·¯å¾„>
    cmd = [
        "modal", "volume", "get", 
        "data",           # å¿…é¡»ä¸ä½ å®šä¹‰çš„ Volume åç§°ä¸€è‡´
        remote_file,      # è¿œç¨‹æºæ–‡ä»¶
        str(local_file)       # æœ¬åœ°ç›®æ ‡æ–‡ä»¶
    ]
    
    retry_count = 5
    for i in range(retry_count):
        try:
            # capture_output=True ä¼šæ•è· stdout/stderrï¼Œä¸è®©å®ƒåˆ·å±
            # check=True ä¼šåœ¨å‘½ä»¤å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
            subprocess.run(cmd, check=True, text=True)
            print(f"ğŸ‰ ä¸‹è½½æˆåŠŸ: {local_path}")
            return True
        except subprocess.CalledProcessError as e:
            # å¦‚æœä¸‹è½½å¤±è´¥ï¼ˆä¾‹å¦‚è¿œç¨‹æ–‡ä»¶ä¸å­˜åœ¨ï¼‰ï¼Œæ‰“å°é”™è¯¯ä¿¡æ¯
            print(f"âŒ ä¸‹è½½å¤±è´¥: {e}, é‡è¯• {i+1}/{retry_count}, sleep {2 ** i}s")
            sleep(2 ** i)
    return False

# 3. è¿™å°±æ˜¯ä½ æƒ³è¦çš„ upload å‡½æ•°
def uploadIfNotExist(local_path: str, remote_filename: str):
    local_file = Path(local_path)
    if not local_file.exists():
        raise FileNotFoundError(f"æœ¬åœ°æ–‡ä»¶æœªæ‰¾åˆ°: {local_path}")

    print(f"ğŸ” æ£€æŸ¥äº‘ç«¯æ–‡ä»¶: {remote_filename} ...")
    
    # è°ƒç”¨ä¸Šé¢çš„äº‘ç«¯å‡½æ•°è¿›è¡Œæ£€æŸ¥
    exists, size_mb = check_file_exists.remote(remote_filename)
    
    if exists:
        print(f"âœ… æ–‡ä»¶å·²å­˜åœ¨ ({size_mb:.2f} MB)ï¼Œè·³è¿‡ä¸Šä¼ ã€‚")
        return

    print(f"ğŸ“¤ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¼€å§‹ä¸Šä¼ : {local_path} (è¿™å¯èƒ½éœ€è¦ä¸€ç‚¹æ—¶é—´)...")
    
    # ã€å…³é”®ä¿®æ”¹ã€‘ä½¿ç”¨ Modal CLI ä¸Šä¼ 
    # è¿™ç»•è¿‡äº† Python å‡½æ•°å‚æ•°çš„å¤§å°é™åˆ¶ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œå¤§æ–‡ä»¶
    # æ ¼å¼: modal volume put <Volumeå> <æœ¬åœ°è·¯å¾„> <è¿œç¨‹ç›®æ ‡è·¯å¾„>
    cmd = [
        "modal", "volume", "put", 
        "data",           # Volume åç§°
        str(local_file),      # æœ¬åœ°æ–‡ä»¶
        remote_filename       # è¿œç¨‹è·¯å¾„ (æ³¨æ„ï¼šè¿™é‡Œä¸éœ€è¦åŠ  /data å‰ç¼€ï¼ŒCLIä¼šè‡ªåŠ¨å¤„ç†)
    ]
    
    # æ‰§è¡Œå‘½ä»¤
    result = subprocess.run(cmd, capture_output=True, text=True)
    
    if result.returncode == 0:
        print(f"ğŸ‰ ä¸Šä¼ æˆåŠŸ: {remote_filename}")
    else:
        # å¦‚æœå‡ºé”™ï¼Œæ‰“å°é”™è¯¯æ—¥å¿—
        raise RuntimeError(f"âŒ ä¸Šä¼ å¤±è´¥: {result.stderr}")

# --- ä½¿ç”¨ç¤ºä¾‹ ---
# if __name__ == "__main__":
#     # å®šä¹‰ä½ è¦å¤„ç†çš„æ–‡ä»¶
#     local_file_path = "/Users/toddzheng/.ktv_control_plane/data/EqCmAYywrwI/original.wav"
#     local_video_path = "/Users/toddzheng/.ktv_control_plane/data/EqCmAYywrwI/video_only.mp4"

    
#     # å®šä¹‰åœ¨äº‘ç«¯ Volume ä¸­çš„ç›¸å¯¹è·¯å¾„ (ä¸è¦ä»¥ / å¼€å¤´ï¼Œä¹Ÿä¸è¦åŠ  /data)
#     # ç»“æœä¼šå­˜åˆ°: /data/EqCmAYywrwI/original.wav
#     remote_relative_path = "EqCmAYywrwI/original.wav"
#     original_relative_path = "EqCmAYywrwI/vocals.wav"
#     video_relative_path = "EqCmAYywrwI/video_only.mp4"

#     local_path = Path("/Users/toddzheng/.ktv_control_plane/data/EqCmAYywrwI/")
#     remote_path = "EqCmAYywrwI"
#     # å¯åŠ¨ Modal App ä¸Šä¸‹æ–‡
#     with app.run():
#         try:
#             # 1. ä¸Šä¼ 
#             # uploadIfNotExist(local_file_path, remote_relative_path)
#             # uploadIfNotExist(local_video_path, video_relative_path)
            
#             # # 2. è°ƒç”¨ GPU å‡½æ•°
#             # print("ğŸš€ è°ƒç”¨è¿œç¨‹ GPU è¿›è¡Œåˆ†ç¦»...")
#             # result = demucsFn.remote(remote_relative_path)
            
#             # print("\nâœ… å¤„ç†å®Œæˆï¼ç»“æœæ–‡ä»¶è·¯å¾„ï¼š")
#             # print(f"   ğŸ¤ äººå£°: {result['vocals']}")
#             # print(f"   ğŸ¹ ä¼´å¥: {result['instrumental']}")
#             # result = transcribe.remote(original_relative_path)
#             # print(result)
#             vocal_file = "vocals.wav"
#             original_file = "original.wav"
#             instrumental_file = "instrumental.wav"
#             if not download_if_not_exist(f"{remote_path}/{vocal_file}", f"{local_path}/{vocal_file}"):
#                 raise FileNotFoundError(f"äººå£°æ–‡ä»¶æœªæ‰¾åˆ°: {remote_path}/{vocal_file}")
#             if not download_if_not_exist(f"{remote_path}/{original_file}", f"{local_path}/{original_file}"):
#                 raise FileNotFoundError(f"åŸå§‹æ–‡ä»¶æœªæ‰¾åˆ°: {remote_path}/{original_file}")
#             if not download_if_not_exist(f"{remote_path}/{instrumental_file}", f"{local_path}/{instrumental_file}"):
#                 raise FileNotFoundError(f"ä¼´å¥æ–‡ä»¶æœªæ‰¾åˆ°: {remote_path}/{instrumental_file}")

            
#         except Exception as e:
#             print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")